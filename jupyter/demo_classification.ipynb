{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Демонстрационный файл\n",
    "\n",
    "> Программа выполняет классификацию корпуса текстов \n",
    "> на основе заготовленных входных и выходных векторов\n",
    "> в БД SQLite. Настройки пути файла БД и параметры \n",
    "> обучения нейронной сети задаются файлом param.json\n",
    "\n",
    "\n",
    "**Подключение внешних библиотек:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from DbInteraction import DbInteraction\n",
    "from Param import Param\n",
    "import time\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Инициализация работы с БД:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'param.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-20d742e12c4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#инициализация класса с параметрами работы\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpathToDB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetPathToDBForReport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDbInteraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#иниц. класса для работы с БД\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitNNAnalysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathToDB\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# отправка в него пути к БД\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# добавить новую строку\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python_nlp/python_nlp/Param.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'param.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'param.json'"
     ]
    }
   ],
   "source": [
    "p = Param() #инициализация класса с параметрами работы\n",
    "pathToDB = p.getPathToDBForReport()\n",
    "db = DbInteraction() #иниц. класса для работы с БД\n",
    "db.initNNAnalysis(pathToDB) # отправка в него пути к БД\n",
    "db.addInfo() # добавить новую строку\n",
    "actualNumberOfData = db.getInfoSize() # узнать номер последней строки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Получение дополнительных параметров для работы и отчета:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t = time.localtime()\n",
    "compilationTime = \"{0}.{1}.{2} {3}:{4}\".format(t.tm_year, t.tm_mon, \n",
    "                                               t.tm_mday, t.tm_hour, \n",
    "                                               t.tm_min)\n",
    "inputSize = db.getInfoData('dictionarySize', 1)[0][0]\n",
    "outputSize = db.getInfoData('numOfTopics', 1)[0][0]\n",
    "corpusSize = db.getInfoData('numOfTexts', 1)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Настройка объекта для последовательного извлечения \n",
    "входных и выходных данных:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = db.getConnectionData()\n",
    "ds = tf.data.Dataset.from_generator(\n",
    "    db.generator(corpusSize, db.getDataCorpusName(), 'inputVector', 'outputVector'),\n",
    "    output_types=(tf.float64, tf.float64),\n",
    "    output_shapes=(tf.TensorShape((inputSize, )), tf.TensorShape((outputSize, ))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Разделение данных на обучающую и тестовую:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.shuffle(buffer_size=corpusSize,\n",
    "                reshuffle_each_iteration=True)\n",
    "trainSize = int(corpusSize*p.getTrainPercentage()/100)\n",
    "ds_train = ds.take(trainSize)\n",
    "ds_val = ds.skip(trainSize)\n",
    "ds = None\n",
    "\n",
    "ds_train = ds_train.batch(30)\n",
    "ds_val = ds_val.batch(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Формирование и подготовка нейронной сети:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(layers.Dense(inputSize, activation='relu'))\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(outputSize, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.01),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Начало процесса обучения сети:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime = time.time() \n",
    "history = model.fit(ds_train,\n",
    "                    epochs=100,\n",
    "                    validation_data=ds_val)\n",
    "endTime = time.time() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Построение графиков для отчета:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summarize history for accuracy\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['val_categorical_accuracy', 'categorical_accuracy'], loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "#summarize history for loss\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss', 'val_loss'], loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Подготовка данных для отчета:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultFull = json.dumps(history.history)\n",
    "resultFull = resultFull.replace('\"', '\"\"') \n",
    "catAccArray = history.history['categorical_accuracy']\n",
    "resultVal1 = json.dumps(catAccArray[len(catAccArray)-1]) \n",
    "# <- last model accuracy categorical_accuracy\n",
    "valCatAccArray = history.history['val_categorical_accuracy']\n",
    "resultVal2 = json.dumps(valCatAccArray[len(valCatAccArray)-1]) \n",
    "# <- last val accuracy val_categorical_accuracy\n",
    "learningTime = json.dumps(endTime-startTime)\n",
    "compilationTime2 = \"{0}-{1}-{2} {3}-{4}\".format(t.tm_year, t.tm_mon, \n",
    "                                               t.tm_mday, t.tm_hour, \n",
    "                                               t.tm_min)\n",
    "nameOfSavedModel = \"model_\"+p.readName()+\"_\"+compilationTime2+\".h5\"\n",
    "neuralNetworkStruct = json.dumps(nameOfSavedModel)\n",
    "neuralNetworkStruct = neuralNetworkStruct.replace('\"', '') \n",
    "model.save(\"savedModels/\"+nameOfSavedModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сохранение результатов работы программы в БД:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.updateInfo('resultVal1', resultVal1, actualNumberOfData)\n",
    "db.updateInfo('resultVal2', resultVal2, actualNumberOfData)\n",
    "db.updateInfo('resultFull', resultFull, actualNumberOfData)\n",
    "db.updateInfo('learningTime', learningTime, actualNumberOfData)\n",
    "db.updateInfo('compilationTime', compilationTime, actualNumberOfData)\n",
    "db.updateInfo('neuralNetworkStruct', neuralNetworkStruct, actualNumberOfData)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
